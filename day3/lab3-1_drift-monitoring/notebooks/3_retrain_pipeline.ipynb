{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3-1: Auto-Retraining Pipeline\n",
    "\n",
    "## Part 3: ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **Driftê°€ ê°ì§€ë˜ë©´ ìë™ìœ¼ë¡œ ëª¨ë¸ì„ ì¬í•™ìŠµ**í•˜ê³  ë°°í¬í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•™ìŠµ ëª©í‘œ\n",
    "- Drift ê°ì§€ ì‹œ ìë™ ì¬í•™ìŠµ\n",
    "- ì¡°ê±´ë¶€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "- MLflowì— ëª¨ë¸ ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "\n",
    "### íŒŒì´í”„ë¼ì¸ êµ¬ì¡°\n",
    "```\n",
    "Check Drift â†’ Retrain Model â†’ Deploy Model\n",
    "    â†“              â†“              â†“\n",
    "MLflow ì¡°íšŒ    ëª¨ë¸ í•™ìŠµ       KServe ë°°í¬\n",
    "(Score>0.3)   MAE: 0.39      (ì‹œë®¬ë ˆì´ì…˜)\n",
    "```\n",
    "\n",
    "### í•µì‹¬ ê°œë…: ì¡°ê±´ë¶€ ë¶„ê¸°\n",
    "- Drift Scoreê°€ **0.3 ì´ìƒ**ì´ë©´ ì¬í•™ìŠµ ìˆ˜í–‰\n",
    "- Drift Scoreê°€ **0.3 ë¯¸ë§Œ**ì´ë©´ ì¬í•™ìŠµ ê±´ë„ˆë›°ê¸°\n",
    "- ë¶ˆí•„ìš”í•œ ì¬í•™ìŠµì„ ë°©ì§€í•˜ì—¬ ë¦¬ì†ŒìŠ¤ ì ˆì•½\n",
    "\n",
    "### ì†Œìš” ì‹œê°„: ì•½ 30ë¶„\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: KFP SDK ì„¤ì¹˜ (í•„ìˆ˜!)\n",
    "\n",
    "âš ï¸ **ì¤‘ìš”**: ì•„ë˜ ì…€ì„ ì‹¤í–‰í•œ í›„ **ë°˜ë“œì‹œ ì»¤ë„ì„ ì¬ì‹œì‘**í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- ë©”ë‰´: **Kernel â†’ Restart Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kfp==2.7.0 -q\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KFP SDK installed!\")\n",
    "print(\"Please restart the kernel: Kernel -> Restart Kernel\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: í™˜ê²½ ì„¤ì •\n",
    "\n",
    "âš ï¸ **ì»¤ë„ ì¬ì‹œì‘ í›„ ì´ ì…€ë¶€í„° ì‹¤í–‰í•˜ì„¸ìš”!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: Change to your USER_NUM!\n",
    "# ============================================================\n",
    "USER_NUM = \"01\"  # ex: \"01\", \"02\", ..., \"11\", \"20\"\n",
    "\n",
    "# Auto configuration\n",
    "NAMESPACE = f\"kubeflow-user{USER_NUM}\"\n",
    "MLFLOW_TRACKING_URI = f\"http://mlflow-server.kubeflow-user{USER_NUM}.svc.cluster.local:5000\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  USER_NUM: {USER_NUM}\")\n",
    "print(f\"  NAMESPACE: {NAMESPACE}\")\n",
    "print(f\"  MLFLOW_URI: {MLFLOW_TRACKING_URI}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp import compiler\n",
    "\n",
    "import kfp\n",
    "print(f\"KFP Version: {kfp.__version__}\")\n",
    "\n",
    "version = kfp.__version__.split('.')\n",
    "if int(version[0]) < 2 or (int(version[0]) == 2 and int(version[1]) < 7):\n",
    "    print(\"Warning: KFP version is less than 2.7.0!\")\n",
    "else:\n",
    "    print(\"KFP version OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Component 1 - Drift í™•ì¸ ë° ì¬í•™ìŠµ ê²°ì •\n",
    "\n",
    "**MLflowì—ì„œ ìµœê·¼ Drift Scoreë¥¼ ì¡°íšŒ**í•˜ê³  ì¬í•™ìŠµ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ë¡œì§\n",
    "1. MLflowì—ì„œ ê°€ì¥ ìµœê·¼ Runì˜ `drift_score` ë©”íŠ¸ë¦­ ì¡°íšŒ\n",
    "2. `drift_score > drift_threshold`ì´ë©´ ì¬í•™ìŠµ í•„ìš”\n",
    "3. ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜\n",
    "\n",
    "### MLflowì—ì„œ Run ì¡°íšŒ\n",
    "```python\n",
    "runs = mlflow.search_runs(\n",
    "    order_by=[\"start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "drift_score = runs.iloc[0]['metrics.drift_score']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow URI (Pipeline parameter)\n",
    "mlflow_uri_for_pipeline = MLFLOW_TRACKING_URI\n",
    "print(f\"MLflow URI: {mlflow_uri_for_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"mlflow==2.9.2\", \"pandas==2.0.3\"]\n",
    ")\n",
    "def check_drift_and_decide(drift_threshold: float, mlflow_uri: str) -> str:\n",
    "    \"\"\"Check recent drift score and decide whether to retrain\"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    print(f\"Drift Threshold: {drift_threshold}\")\n",
    "    \n",
    "    drift_score = 0.0\n",
    "    should_retrain = True  # Default: retrain if cannot check\n",
    "    \n",
    "    try:\n",
    "        import mlflow\n",
    "        \n",
    "        print(f\"Connecting to MLflow: {mlflow_uri}\")\n",
    "        os.environ['MLFLOW_TRACKING_URI'] = mlflow_uri\n",
    "        mlflow.set_tracking_uri(mlflow_uri)\n",
    "        \n",
    "        try:\n",
    "            mlflow.set_experiment(\"drift-monitoring\")\n",
    "            \n",
    "            # Query recent Run\n",
    "            runs = mlflow.search_runs(\n",
    "                order_by=[\"start_time DESC\"],\n",
    "                max_results=1\n",
    "            )\n",
    "            \n",
    "            if len(runs) > 0 and 'metrics.drift_score' in runs.columns:\n",
    "                drift_score = float(runs.iloc[0]['metrics.drift_score'])\n",
    "                should_retrain = drift_score > drift_threshold\n",
    "                print(f\"Found drift score from MLflow: {drift_score:.2f}\")\n",
    "            else:\n",
    "                print(\"No previous runs found, defaulting to retrain\")\n",
    "                should_retrain = True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"MLflow experiment error: {e}\")\n",
    "            should_retrain = True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"MLflow connection failed: {e}\")\n",
    "        should_retrain = True\n",
    "    \n",
    "    result = {\n",
    "        'should_retrain': bool(should_retrain),\n",
    "        'drift_score': float(drift_score)\n",
    "    }\n",
    "    \n",
    "    print(f\"Decision:\")\n",
    "    print(f\"  Drift Score: {drift_score:.2f}\")\n",
    "    print(f\"  Should Retrain: {should_retrain}\")\n",
    "    \n",
    "    return json.dumps(result)\n",
    "\n",
    "print(\"Component 1: check_drift_and_decide defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Component 2 - ëª¨ë¸ ì¬í•™ìŠµ\n",
    "\n",
    "**California Housing ë°ì´í„°ì…‹**ì„ ì‚¬ìš©í•˜ì—¬ **RandomForest ëª¨ë¸**ì„ í•™ìŠµí•˜ê³ , **MLflowì— ë©”íŠ¸ë¦­ì„ ê¸°ë¡**í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•™ìŠµ íŒŒë¼ë¯¸í„°\n",
    "| íŒŒë¼ë¯¸í„° | ê°’ |\n",
    "|---------|----|\n",
    "| ì•Œê³ ë¦¬ì¦˜ | RandomForestRegressor |\n",
    "| n_estimators | 100 |\n",
    "| í‰ê°€ ë©”íŠ¸ë¦­ | MAE (Mean Absolute Error) |\n",
    "\n",
    "### ë°ì´í„°ì…‹: California Housing\n",
    "- ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ì˜ˆì¸¡\n",
    "- 8ê°œ íŠ¹ì„± (MedInc, HouseAge, AveRooms ë“±)\n",
    "- íƒ€ê²Ÿ: MedHouseVal (ì¤‘ìœ„ ì£¼íƒ ê°€ê²©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas==2.0.3\", \"numpy\", \"scikit-learn==1.3.2\", \"mlflow==2.9.2\"]\n",
    ")\n",
    "def retrain_model(train_size: int, mlflow_uri: str) -> str:\n",
    "    \"\"\"Retrain model with California Housing dataset\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    import json\n",
    "    import os\n",
    "    import uuid\n",
    "    \n",
    "    print(f\"Loading training data...\")\n",
    "    \n",
    "    # Load data\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "    \n",
    "    # Sample training data\n",
    "    train_data = df.sample(n=train_size, random_state=42)\n",
    "    print(f\"Training data: {len(train_data)} samples\")\n",
    "    \n",
    "    X = train_data.drop('MedHouseVal', axis=1)\n",
    "    y = train_data['MedHouseVal']\n",
    "    \n",
    "    # Train/Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training RandomForest model...\")\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "    # Model version\n",
    "    model_version = str(uuid.uuid4())[:8]\n",
    "    \n",
    "    print(f\"Training Results:\")\n",
    "    print(f\"  Model version: {model_version}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    try:\n",
    "        import mlflow\n",
    "        \n",
    "        print(f\"Connecting to MLflow: {mlflow_uri}\")\n",
    "        os.environ['MLFLOW_TRACKING_URI'] = mlflow_uri\n",
    "        mlflow.set_tracking_uri(mlflow_uri)\n",
    "        \n",
    "        try:\n",
    "            mlflow.set_experiment(\"auto-retraining\")\n",
    "        except:\n",
    "            mlflow.create_experiment(\"auto-retraining\")\n",
    "            mlflow.set_experiment(\"auto-retraining\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=\"retrained-model\"):\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            mlflow.log_param(\"n_estimators\", 100)\n",
    "            mlflow.log_param(\"train_size\", train_size)\n",
    "            model_version = mlflow.active_run().info.run_id[:8]\n",
    "        \n",
    "        print(\"Metrics logged to MLflow successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"MLflow logging failed: {e}\")\n",
    "    \n",
    "    result = {\n",
    "        'model_version': str(model_version),\n",
    "        'mae': float(mae),\n",
    "        'status': 'trained'\n",
    "    }\n",
    "    \n",
    "    print(f\"Model trained successfully!\")\n",
    "    \n",
    "    return json.dumps(result)\n",
    "\n",
    "print(\"Component 2: retrain_model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Component 3 - ëª¨ë¸ ë°°í¬\n",
    "\n",
    "ì¬í•™ìŠµëœ ëª¨ë¸ì„ **ë°°í¬**í•©ë‹ˆë‹¤ (ì‹œë®¬ë ˆì´ì…˜).\n",
    "\n",
    "### ì‹¤ì œ í™˜ê²½ì—ì„œëŠ”:\n",
    "- KServe InferenceService ì—…ë°ì´íŠ¸\n",
    "- ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°\n",
    "- Blue/Green ë˜ëŠ” Canary ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(base_image=\"python:3.9-slim\")\n",
    "def deploy_model(model_result: str) -> str:\n",
    "    \"\"\"Deploy model simulation\"\"\"\n",
    "    import json\n",
    "    \n",
    "    result = json.loads(model_result)\n",
    "    model_version = result['model_version']\n",
    "    mae = result['mae']\n",
    "    \n",
    "    print(f\"Deploying model version: {model_version}\")\n",
    "    print(f\"Model MAE: {mae:.4f}\")\n",
    "    print(\"Model deployed successfully!\")\n",
    "    \n",
    "    return \"deployed\"\n",
    "\n",
    "print(\"Component 3: deploy_model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Pipeline ì •ì˜\n",
    "\n",
    "ìœ„ì—ì„œ ì •ì˜í•œ **3ê°œì˜ ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°**í•˜ì—¬ ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### íŒŒì´í”„ë¼ì¸ íë¦„\n",
    "```\n",
    "1. check_task: MLflowì—ì„œ Drift Score í™•ì¸ & ì¬í•™ìŠµ ê²°ì •\n",
    "2. retrain_task: ëª¨ë¸ ì¬í•™ìŠµ (check_task ì™„ë£Œ í›„ ì‹¤í–‰)\n",
    "3. deploy_task: ëª¨ë¸ ë°°í¬ (retrain_task ì™„ë£Œ í›„ ì‹¤í–‰)\n",
    "```\n",
    "\n",
    "### ì‹¤í–‰ ìˆœì„œ ì œì–´: `.after()`\n",
    "```python\n",
    "retrain_task = retrain_model(...)\n",
    "retrain_task.after(check_task)  # check_task ì™„ë£Œ í›„ retrain_task ì‹¤í–‰\n",
    "```\n",
    "\n",
    "`.output`ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ `.after()`ë¡œ ìˆœì„œë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"auto-retrain\",\n",
    "    description=\"auto retraining pipeline\"\n",
    ")\n",
    "def auto_retrain_pipeline(\n",
    "    drift_threshold: float = 0.3,\n",
    "    train_size: int = 5000,\n",
    "    mlflow_uri: str = mlflow_uri_for_pipeline\n",
    "):\n",
    "    \"\"\"Auto retraining pipeline\"\"\"\n",
    "    \n",
    "    # Step 1: Check drift and decide\n",
    "    check_task = check_drift_and_decide(\n",
    "        drift_threshold=drift_threshold,\n",
    "        mlflow_uri=mlflow_uri\n",
    "    )\n",
    "    \n",
    "    # Step 2: Retrain model (after check_task)\n",
    "    retrain_task = retrain_model(\n",
    "        train_size=train_size,\n",
    "        mlflow_uri=mlflow_uri\n",
    "    )\n",
    "    retrain_task.after(check_task)  # Sequential execution\n",
    "    \n",
    "    # Step 3: Deploy model\n",
    "    deploy_task = deploy_model(model_result=retrain_task.output)\n",
    "\n",
    "print(\"Pipeline defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Pipeline ì»´íŒŒì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_filename = 'auto_retrain_pipeline.yaml'\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=auto_retrain_pipeline,\n",
    "    package_path=pipeline_filename\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"  Pipeline compiled successfully!\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"  Output file: {pipeline_filename}\")\n",
    "print()\n",
    "print(\"  Next steps:\")\n",
    "print(\"    1. Upload pipeline to Kubeflow UI\")\n",
    "print(\"    2. Click 'Create Run'\")\n",
    "print(\"    3. Set parameters and Start\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: ìƒì„±ëœ YAML íŒŒì¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pipeline_filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    print(f\"File: {pipeline_filename} (first 30 lines)\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, line in enumerate(lines[:30]):\n",
    "        print(f\"{i+1:3d} | {line}\", end='')\n",
    "    if len(lines) > 30:\n",
    "        print(f\"\\n... ({len(lines)} lines total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Kubeflow UIì—ì„œ ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "### Step 1: Pipeline ì—…ë¡œë“œ\n",
    "1. Kubeflow UI â†’ **\"Pipelines\"** í´ë¦­\n",
    "2. **\"+ Upload pipeline\"** ë²„íŠ¼ í´ë¦­\n",
    "3. `auto_retrain_pipeline.yaml` íŒŒì¼ ì„ íƒ\n",
    "4. **\"Create\"** ë²„íŠ¼ í´ë¦­\n",
    "\n",
    "### Step 2: Run ìƒì„±\n",
    "1. íŒŒì´í”„ë¼ì¸ í´ë¦­ â†’ **\"+ Create run\"** ë²„íŠ¼ í´ë¦­\n",
    "2. Parameters ì„¤ì •:\n",
    "   - `drift_threshold`: 0.3\n",
    "   - `train_size`: 5000\n",
    "   - `mlflow_uri`: ìë™ ì…ë ¥ë¨\n",
    "3. **\"Start\"** ë²„íŠ¼ í´ë¦­\n",
    "\n",
    "### Step 3: ì‹¤í–‰ ê²°ê³¼ í™•ì¸\n",
    "\n",
    "**Graph íƒ­ì—ì„œ í™•ì¸:**\n",
    "```\n",
    "âœ… check-drift-and-decide: Succeeded\n",
    "âœ… retrain-model: Succeeded\n",
    "âœ… deploy-model: Succeeded\n",
    "```\n",
    "\n",
    "**ì˜ˆìƒ ë¡œê·¸:**\n",
    "```\n",
    "Drift Score: 0.11\n",
    "Should Retrain: False\n",
    "\n",
    "Loading training data...\n",
    "Training data: 5000 samples\n",
    "Model trained successfully\n",
    "Model version: db4b3de4\n",
    "MAE: 0.3901\n",
    "\n",
    "Deploying model version: db4b3de4\n",
    "Model deployed successfully!\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Part 3 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] KFP SDK 2.7.0 ì´ìƒ ì„¤ì¹˜ ì™„ë£Œ\n",
    "- [ ] USER_NUM ì„¤ì • ì™„ë£Œ\n",
    "- [ ] `auto_retrain_pipeline.yaml` íŒŒì¼ ìƒì„± ì™„ë£Œ\n",
    "- [ ] Kubeflow UIì— íŒŒì´í”„ë¼ì¸ ì—…ë¡œë“œ ì™„ë£Œ\n",
    "- [ ] íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ\n",
    "- [ ] 3ê°œ ì»´í¬ë„ŒíŠ¸ ëª¨ë‘ ë…¹ìƒ‰ ì²´í¬ í™•ì¸\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š í•µì‹¬ ê°œë… ì •ë¦¬\n",
    "\n",
    "### 1. ì»´í¬ë„ŒíŠ¸ ì‹¤í–‰ ìˆœì„œ ì œì–´\n",
    "\n",
    "| ë°©ë²• | ì„¤ëª… | ì˜ˆì‹œ |\n",
    "|------|------|------|\n",
    "| `.output` | ë°ì´í„° ì „ë‹¬ + ìˆœì„œ ì œì–´ | `step2 = comp2(input=step1.output)` |\n",
    "| `.after()` | ìˆœì„œë§Œ ì œì–´ (ë°ì´í„° ì „ë‹¬ X) | `step2.after(step1)` |\n",
    "\n",
    "### 2. ì¬í•™ìŠµ ì „ëµ\n",
    "\n",
    "| ì „ëµ | ì„¤ëª… | ì¥ì  | ë‹¨ì  |\n",
    "|------|------|------|------|\n",
    "| **íŠ¸ë¦¬ê±° ê¸°ë°˜** | Drift ê°ì§€ ì‹œ ì¦‰ì‹œ ì¬í•™ìŠµ | ë¹ ë¥¸ ëŒ€ì‘ | ë¹„ìš© ë†’ìŒ |\n",
    "| **ìŠ¤ì¼€ì¤„ ê¸°ë°˜** | ì •í•´ì§„ ì£¼ê¸°ë¡œ ì¬í•™ìŠµ | ì˜ˆì¸¡ ê°€ëŠ¥ | ëŒ€ì‘ ëŠ¦ìŒ |\n",
    "| **í•˜ì´ë¸Œë¦¬ë“œ** | ë‘˜ ë‹¤ ë³‘í–‰ | ê· í˜• | ë³µì¡ì„± |\n",
    "\n",
    "### 3. MLflow ì‹¤í—˜ ì¡°íšŒ\n",
    "```python\n",
    "runs = mlflow.search_runs(\n",
    "    order_by=[\"start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "drift_score = runs.iloc[0]['metrics.drift_score']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Lab 3-1 ì „ì²´ ì™„ë£Œ!\n",
    "\n",
    "### í•™ìŠµí•œ ë‚´ìš© ìš”ì•½\n",
    "\n",
    "| Part | ë‚´ìš© | í•µì‹¬ ê¸°ìˆ  |\n",
    "|------|------|----------|\n",
    "| **Part 1** | Drift Detection | KS Test, Drift Score |\n",
    "| **Part 2** | Monitoring Pipeline | Kubeflow Pipeline, MLflow |\n",
    "| **Part 3** | Auto-Retraining | ìˆœì„œ ì œì–´, ìë™í™” |\n",
    "\n",
    "### ì „ì²´ MLOps ëª¨ë‹ˆí„°ë§ ì‚¬ì´í´\n",
    "```\n",
    "1. ë°ì´í„° ìˆ˜ì§‘ â†’ 2. Drift ê°ì§€ â†’ 3. ì•Œë¦¼ ë°œì†¡\n",
    "       â†‘                              â†“\n",
    "6. ë°°í¬ â† 5. ëª¨ë¸ í•™ìŠµ â† 4. ì¬í•™ìŠµ ê²°ì •\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
