{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3-1: Drift Monitoring Pipeline\n",
    "\n",
    "## Part 2: ëª¨ë‹ˆí„°ë§ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” Kubeflow Pipelineì„ í™œìš©í•˜ì—¬ **Data Drift ëª¨ë‹ˆí„°ë§ì„ ìë™í™”**í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•™ìŠµ ëª©í‘œ\n",
    "- Kubeflow Pipelineìœ¼ë¡œ Drift ëª¨ë‹ˆí„°ë§ ìë™í™”\n",
    "- MLflowì— ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "- Alert ì‹œìŠ¤í…œ êµ¬ì¶• (ì‹œë®¬ë ˆì´ì…˜)\n",
    "\n",
    "### íŒŒì´í”„ë¼ì¸ êµ¬ì¡°\n",
    "```\n",
    "Collect Data â†’ Detect Drift â†’ Log Metrics â†’ Send Alert\n",
    "    â†“              â†“              â†“             â†“\n",
    "  1000ìƒ˜í”Œ      Drift Score    MLflow        Slack/Email\n",
    "               (KS Test)       ê¸°ë¡          ì‹œë®¬ë ˆì´ì…˜\n",
    "```\n",
    "\n",
    "### ì†Œìš” ì‹œê°„: ì•½ 30ë¶„\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: KFP SDK ì„¤ì¹˜ (í•„ìˆ˜!)\n",
    "\n",
    "âš ï¸ **ì¤‘ìš”**: ì•„ë˜ ì…€ì„ ì‹¤í–‰í•œ í›„ **ë°˜ë“œì‹œ ì»¤ë„ì„ ì¬ì‹œì‘**í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- ë©”ë‰´: **Kernel â†’ Restart Kernel**\n",
    "- ë˜ëŠ” ë‹¨ì¶•í‚¤: `0` ë‘ ë²ˆ ì—°ì† ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kfp==2.7.0 -q\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KFP SDK installed!\")\n",
    "print(\"Please restart the kernel: Kernel -> Restart Kernel\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: í™˜ê²½ ì„¤ì •\n",
    "\n",
    "âš ï¸ **ì»¤ë„ ì¬ì‹œì‘ í›„ ì´ ì…€ë¶€í„° ì‹¤í–‰í•˜ì„¸ìš”!**\n",
    "\n",
    "ë³¸ì¸ì˜ ì‚¬ìš©ì ë²ˆí˜¸(`USER_NUM`)ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: Change to your USER_NUM!\n",
    "# ============================================================\n",
    "USER_NUM = \"01\"  # ex: \"01\", \"02\", ..., \"11\", \"20\"\n",
    "\n",
    "# Auto configuration\n",
    "NAMESPACE = f\"kubeflow-user{USER_NUM}\"\n",
    "MLFLOW_TRACKING_URI = f\"http://mlflow-server.kubeflow-user{USER_NUM}.svc.cluster.local:5000\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  USER_NUM: {USER_NUM}\")\n",
    "print(f\"  NAMESPACE: {NAMESPACE}\")\n",
    "print(f\"  MLFLOW_URI: {MLFLOW_TRACKING_URI}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ë²„ì „ í™•ì¸\n",
    "\n",
    "KFP SDKë¥¼ ì„í¬íŠ¸í•˜ê³  ë²„ì „ì„ í™•ì¸í•©ë‹ˆë‹¤. **2.7.0 ì´ìƒ**ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp import compiler\n",
    "\n",
    "import kfp\n",
    "print(f\"KFP Version: {kfp.__version__}\")\n",
    "\n",
    "version = kfp.__version__.split('.')\n",
    "if int(version[0]) < 2 or (int(version[0]) == 2 and int(version[1]) < 7):\n",
    "    print(\"Warning: KFP version is less than 2.7.0!\")\n",
    "    print(\"Please run Step 0 and restart the kernel.\")\n",
    "else:\n",
    "    print(\"KFP version OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Component 1 - í”„ë¡œë•ì…˜ ë°ì´í„° ìˆ˜ì§‘\n",
    "\n",
    "í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.  \n",
    "ì‹¤ìŠµì—ì„œëŠ” **ì‹œë®¬ë ˆì´ì…˜**ìœ¼ë¡œ ìƒ˜í”Œ ì‚¬ì´ì¦ˆë§Œ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "### KFP Component ì •ì˜ ë°©ë²•\n",
    "```python\n",
    "@dsl.component(base_image=\"python:3.9-slim\")\n",
    "def my_component(input: int) -> int:\n",
    "    # ë¡œì§ ì‘ì„±\n",
    "    return output\n",
    "```\n",
    "\n",
    "- `@dsl.component`: ì»´í¬ë„ŒíŠ¸ ë°ì½”ë ˆì´í„°\n",
    "- `base_image`: ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì§€ì •\n",
    "- **íƒ€ì… íŒíŠ¸ í•„ìˆ˜**: ì…ë ¥/ì¶œë ¥ íƒ€ì…ì„ ë°˜ë“œì‹œ ëª…ì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(base_image=\"python:3.9-slim\")\n",
    "def collect_production_data(sample_size: int = 1000) -> int:\n",
    "    \"\"\"Collect production data simulation\"\"\"\n",
    "    print(f\"Data collection simulated: {sample_size} samples\")\n",
    "    return sample_size\n",
    "\n",
    "print(\"Component 1: collect_production_data defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Component 2 - Drift ê°ì§€\n",
    "\n",
    "ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ **ê¸°ì¤€ ë°ì´í„°(Reference Data)**ì™€ ë¹„êµí•˜ì—¬ **KS Test**ë¥¼ ìˆ˜í–‰í•˜ê³ , **Drift Score**ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "### KS Test (Kolmogorov-Smirnov Test)\n",
    "- ë‘ ë¶„í¬ê°€ ë™ì¼í•œì§€ ê²€ì •í•˜ëŠ” í†µê³„ì  ë°©ë²•\n",
    "- **p-value < 0.05**ì´ë©´ ë¶„í¬ê°€ ë‹¤ë¥´ë‹¤ê³  íŒë‹¨ (Drift ê°ì§€)\n",
    "\n",
    "### Drift Score ê³„ì‚°\n",
    "```\n",
    "Drift Score = (Driftê°€ ê°ì§€ëœ Feature ìˆ˜) / (ì „ì²´ Feature ìˆ˜)\n",
    "```\n",
    "\n",
    "### âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "- `packages_to_install`ë¡œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì§€ì •\n",
    "- **importë¬¸ì€ í•¨ìˆ˜ ë‚´ë¶€ì— ì‘ì„±** (ê° ì»´í¬ë„ŒíŠ¸ëŠ” ë…ë¦½ëœ ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"scikit-learn==1.3.2\", \"pandas==2.0.3\", \"numpy\", \"scipy\"]\n",
    ")\n",
    "def detect_drift(sample_size: int, drift_threshold: float = 0.3) -> str:\n",
    "    \"\"\"Detect drift using KS test\"\"\"\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy.stats import ks_2samp\n",
    "    import json\n",
    "    \n",
    "    print(f\"Loading data for drift detection...\")\n",
    "    \n",
    "    # Load California Housing dataset\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "    \n",
    "    # Reference data (baseline)\n",
    "    reference_data = df.sample(n=2000, random_state=42)\n",
    "    print(f\"Reference data: {len(reference_data)} samples\")\n",
    "    \n",
    "    # Current data (with simulated drift on MedInc feature)\n",
    "    current_data = df.sample(n=sample_size, random_state=123)\n",
    "    current_data = current_data.copy()\n",
    "    current_data['MedInc'] = current_data['MedInc'] * 1.5 + np.random.normal(0, 0.3, len(current_data))\n",
    "    print(f\"Current data: {len(current_data)} samples\")\n",
    "    \n",
    "    # Drift detection using KS Test\n",
    "    n_drifted = 0\n",
    "    for col in reference_data.columns:\n",
    "        _, p_value = ks_2samp(reference_data[col], current_data[col])\n",
    "        if p_value < 0.05:  # Significant difference\n",
    "            n_drifted += 1\n",
    "    \n",
    "    drift_score = n_drifted / len(reference_data.columns)\n",
    "    drift_detected = drift_score > drift_threshold\n",
    "    \n",
    "    result = {\n",
    "        'drift_detected': bool(drift_detected),\n",
    "        'drift_score': float(drift_score),\n",
    "        'n_drifted': int(n_drifted)\n",
    "    }\n",
    "    \n",
    "    print(f\"Drift Score: {drift_score:.2f}\")\n",
    "    print(f\"Drifted Features: {n_drifted}/{len(reference_data.columns)}\")\n",
    "    print(f\"Drift Detected: {drift_detected}\")\n",
    "    \n",
    "    return json.dumps(result)\n",
    "\n",
    "print(\"Component 2: detect_drift defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Component 3 - ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "\n",
    "ê³„ì‚°ëœ Drift Scoreì™€ ê²°ê³¼ë¥¼ **MLflowì— ê¸°ë¡**í•©ë‹ˆë‹¤.  \n",
    "ë‚˜ì¤‘ì— ì¶”ì í•˜ê³  ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### MLflow ì‚¬ìš©ë²•\n",
    "```python\n",
    "mlflow.set_tracking_uri(uri)        # MLflow ì„œë²„ ì—°ê²°\n",
    "mlflow.set_experiment(\"name\")       # Experiment ì„¤ì •\n",
    "with mlflow.start_run():            # Run ì‹œì‘\n",
    "    mlflow.log_metric(\"key\", value) # ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow URI (Pipeline parameter)\n",
    "mlflow_uri_for_pipeline = MLFLOW_TRACKING_URI\n",
    "print(f\"MLflow URI: {mlflow_uri_for_pipeline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"mlflow==2.9.2\"]\n",
    ")\n",
    "def log_metrics(drift_result: str, mlflow_uri: str) -> str:\n",
    "    \"\"\"Log metrics to MLflow\"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    result = json.loads(drift_result)\n",
    "    \n",
    "    print(f\"Drift Score: {result['drift_score']:.2f}\")\n",
    "    print(f\"Drift Detected: {result['drift_detected']}\")\n",
    "    print(f\"Drifted Features: {result['n_drifted']}\")\n",
    "    \n",
    "    try:\n",
    "        import mlflow\n",
    "        \n",
    "        print(f\"Connecting to MLflow: {mlflow_uri}\")\n",
    "        os.environ['MLFLOW_TRACKING_URI'] = mlflow_uri\n",
    "        mlflow.set_tracking_uri(mlflow_uri)\n",
    "        \n",
    "        try:\n",
    "            mlflow.set_experiment(\"drift-monitoring\")\n",
    "        except Exception as e:\n",
    "            print(f\"Creating new experiment...\")\n",
    "            mlflow.create_experiment(\"drift-monitoring\")\n",
    "            mlflow.set_experiment(\"drift-monitoring\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=\"drift-check\"):\n",
    "            mlflow.log_metric(\"drift_score\", result['drift_score'])\n",
    "            mlflow.log_metric(\"drift_detected\", 1 if result['drift_detected'] else 0)\n",
    "            mlflow.log_metric(\"n_drifted\", result['n_drifted'])\n",
    "            mlflow.set_tag(\"pipeline\", \"monitoring\")\n",
    "        \n",
    "        print(\"Metrics logged to MLflow successfully\")\n",
    "        return \"success\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"MLflow logging failed: {e}\")\n",
    "        print(\"Continuing without MLflow...\")\n",
    "        return \"success-no-mlflow\"\n",
    "\n",
    "print(\"Component 3: log_metrics defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Component 4 - ì•Œë¦¼ ë°œì†¡\n",
    "\n",
    "Driftê°€ ê°ì§€ë˜ë©´ **ì•Œë¦¼ì„ ë°œì†¡**í•©ë‹ˆë‹¤.  \n",
    "ì‹¤ìŠµì—ì„œëŠ” **ì½˜ì†” ì¶œë ¥ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜**í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì‹¤ì œ í™˜ê²½ì—ì„œëŠ”:\n",
    "- Slack ì•Œë¦¼\n",
    "- Email ë°œì†¡\n",
    "- PagerDuty ì—°ë™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(base_image=\"python:3.9-slim\")\n",
    "def send_alert(drift_result: str) -> str:\n",
    "    \"\"\"Send alert simulation\"\"\"\n",
    "    import json\n",
    "    \n",
    "    result = json.loads(drift_result)\n",
    "    \n",
    "    if result['drift_detected']:\n",
    "        print(\"ALERT: Data Drift Detected!\")\n",
    "        print(f\"Drift Score: {result['drift_score']:.2f}\")\n",
    "        print(\"Action: Consider model retraining\")\n",
    "        return \"alert-sent\"\n",
    "    else:\n",
    "        print(\"OK: No significant drift detected\")\n",
    "        return \"no-alert\"\n",
    "\n",
    "print(\"Component 4: send_alert defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Pipeline ì •ì˜\n",
    "\n",
    "ìœ„ì—ì„œ ì •ì˜í•œ **4ê°œì˜ ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°**í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### íŒŒì´í”„ë¼ì¸ íë¦„\n",
    "```\n",
    "1. collect_task: í”„ë¡œë•ì…˜ ë°ì´í„° ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "2. detect_task: Drift ê°ì§€ (KS Test ìˆ˜í–‰)\n",
    "3. log_task: MLflowì— ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "4. alert_task: ì•Œë¦¼ ë°œì†¡ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "```\n",
    "\n",
    "### í•µì‹¬ ê°œë…: `.output`ìœ¼ë¡œ ë°ì´í„° ì „ë‹¬\n",
    "```python\n",
    "step1 = component1(input=param)\n",
    "step2 = component2(input=step1.output)  # step1ì˜ ì¶œë ¥ì„ step2ì˜ ì…ë ¥ìœ¼ë¡œ!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"drift-monitoring\",\n",
    "    description=\"drift monitoring pipeline\"\n",
    ")\n",
    "def drift_monitoring_pipeline(\n",
    "    sample_size: int = 1000,\n",
    "    drift_threshold: float = 0.3,\n",
    "    mlflow_uri: str = mlflow_uri_for_pipeline\n",
    "):\n",
    "    \"\"\"Drift monitoring pipeline\"\"\"\n",
    "    \n",
    "    # Step 1: Collect data (simulated)\n",
    "    collect_task = collect_production_data(sample_size=sample_size)\n",
    "    \n",
    "    # Step 2: Detect drift\n",
    "    detect_task = detect_drift(\n",
    "        sample_size=collect_task.output,\n",
    "        drift_threshold=drift_threshold\n",
    "    )\n",
    "    \n",
    "    # Step 3: Log metrics to MLflow\n",
    "    log_task = log_metrics(\n",
    "        drift_result=detect_task.output,\n",
    "        mlflow_uri=mlflow_uri\n",
    "    )\n",
    "    \n",
    "    # Step 4: Send alert\n",
    "    alert_task = send_alert(drift_result=detect_task.output)\n",
    "\n",
    "print(\"Pipeline defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: Pipeline ì»´íŒŒì¼\n",
    "\n",
    "ì •ì˜ëœ íŒŒì´í”„ë¼ì¸ì„ **YAML íŒŒì¼ë¡œ ì»´íŒŒì¼**í•©ë‹ˆë‹¤.  \n",
    "ì´ YAML íŒŒì¼ì„ Kubeflow UIì— ì—…ë¡œë“œí•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_filename = 'drift_monitoring_pipeline.yaml'\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=drift_monitoring_pipeline,\n",
    "    package_path=pipeline_filename\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"  Pipeline compiled successfully!\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"  Output file: {pipeline_filename}\")\n",
    "print()\n",
    "print(\"  Next steps:\")\n",
    "print(\"    1. Upload pipeline to Kubeflow UI\")\n",
    "print(\"    2. Click 'Create Run'\")\n",
    "print(\"    3. Set parameters and Start\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 9: ìƒì„±ëœ YAML íŒŒì¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pipeline_filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    print(f\"File: {pipeline_filename} (first 30 lines)\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, line in enumerate(lines[:30]):\n",
    "        print(f\"{i+1:3d} | {line}\", end='')\n",
    "    if len(lines) > 30:\n",
    "        print(f\"\\n... ({len(lines)} lines total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Kubeflow UIì—ì„œ ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "### Step 1: Pipeline ì—…ë¡œë“œ\n",
    "1. Kubeflow UI ì ‘ì†\n",
    "2. ì™¼ìª½ ë©”ë‰´ì—ì„œ **\"Pipelines\"** í´ë¦­\n",
    "3. ì˜¤ë¥¸ìª½ ìƒë‹¨ì˜ **\"+ Upload pipeline\"** ë²„íŠ¼ í´ë¦­\n",
    "4. `drift_monitoring_pipeline.yaml` íŒŒì¼ ì„ íƒ\n",
    "5. **\"Create\"** ë²„íŠ¼ í´ë¦­\n",
    "\n",
    "### Step 2: Run ìƒì„±\n",
    "1. ì—…ë¡œë“œëœ íŒŒì´í”„ë¼ì¸ í´ë¦­\n",
    "2. **\"+ Create run\"** ë²„íŠ¼ í´ë¦­\n",
    "3. Parameters ì„¤ì •:\n",
    "   - `sample_size`: 1000 (ê¸°ë³¸ê°’)\n",
    "   - `drift_threshold`: 0.3 (ê¸°ë³¸ê°’)\n",
    "   - `mlflow_uri`: ìë™ ì…ë ¥ë¨\n",
    "4. **\"Start\"** ë²„íŠ¼ í´ë¦­\n",
    "\n",
    "### Step 3: ì‹¤í–‰ ê²°ê³¼ í™•ì¸\n",
    "- **Graph íƒ­**ì—ì„œ ê° ì»´í¬ë„ŒíŠ¸ ì‹¤í–‰ ìƒíƒœ í™•ì¸\n",
    "- ê° ì»´í¬ë„ŒíŠ¸ í´ë¦­ â†’ **Logs** íƒ­ì—ì„œ ë¡œê·¸ í™•ì¸\n",
    "\n",
    "### ì˜ˆìƒ ê²°ê³¼\n",
    "```\n",
    "âœ… collect-production-data: Succeeded\n",
    "âœ… detect-drift: Succeeded  \n",
    "âœ… log-metrics: Succeeded\n",
    "âœ… send-alert: Succeeded\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Part 2 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] KFP SDK 2.7.0 ì´ìƒ ì„¤ì¹˜ ì™„ë£Œ\n",
    "- [ ] USER_NUM ì„¤ì • ì™„ë£Œ\n",
    "- [ ] `drift_monitoring_pipeline.yaml` íŒŒì¼ ìƒì„± ì™„ë£Œ\n",
    "- [ ] Kubeflow UIì— íŒŒì´í”„ë¼ì¸ ì—…ë¡œë“œ ì™„ë£Œ\n",
    "- [ ] íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ\n",
    "- [ ] 4ê°œ ì»´í¬ë„ŒíŠ¸ ëª¨ë‘ ë…¹ìƒ‰ ì²´í¬ í™•ì¸\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š í•µì‹¬ ê°œë… ì •ë¦¬\n",
    "\n",
    "### 1. KFP Component ì •ì˜\n",
    "```python\n",
    "@dsl.component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas\", \"numpy\"]\n",
    ")\n",
    "def my_component(input_value: int) -> str:\n",
    "    import pandas as pd  # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import!\n",
    "    result = str(input_value * 2)\n",
    "    return result\n",
    "```\n",
    "\n",
    "### 2. Pipeline ì •ì˜\n",
    "```python\n",
    "@dsl.pipeline(name=\"my-pipeline\")\n",
    "def my_pipeline(param1: int = 10):\n",
    "    step1 = component1(input=param1)\n",
    "    step2 = component2(input=step1.output)  # .outputìœ¼ë¡œ ì—°ê²°!\n",
    "```\n",
    "\n",
    "### 3. ì»´íŒŒì¼\n",
    "```python\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=my_pipeline,\n",
    "    package_path='my_pipeline.yaml'\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”œ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "**Part 3: Auto-Retraining Pipeline**ì—ì„œëŠ” Drift Scoreê°€ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¬í•™ìŠµí•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ ë§Œë“­ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
